[2025-07-05T14:01:28.194+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-05T14:01:28.207+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: practice_etl_pipeline.transform_and_load manual__2025-07-05T14:01:18.047993+00:00 [queued]>
[2025-07-05T14:01:28.210+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: practice_etl_pipeline.transform_and_load manual__2025-07-05T14:01:18.047993+00:00 [queued]>
[2025-07-05T14:01:28.211+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-05T14:01:28.219+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_and_load> on 2025-07-05 14:01:18.047993+00:00
[2025-07-05T14:01:28.222+0000] {clientserver.py:570} INFO - Closing down clientserver connection
[2025-07-05T14:01:28.223+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=9713) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-07-05T14:01:28.224+0000] {standard_task_runner.py:63} INFO - Started process 9849 to run task
[2025-07-05T14:01:28.225+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'practice_etl_pipeline', 'transform_and_load', 'manual__2025-07-05T14:01:18.047993+00:00', '--job-id', '131', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp6bxk7b0i']
[2025-07-05T14:01:28.226+0000] {standard_task_runner.py:91} INFO - Job 131: Subtask transform_and_load
[2025-07-05T14:01:28.259+0000] {task_command.py:426} INFO - Running <TaskInstance: practice_etl_pipeline.transform_and_load manual__2025-07-05T14:01:18.047993+00:00 [running]> on host 93b0937d74ff
[2025-07-05T14:01:28.307+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='practice_etl_pipeline' AIRFLOW_CTX_TASK_ID='transform_and_load' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T14:01:18.047993+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T14:01:18.047993+00:00'
[2025-07-05T14:01:28.309+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-05T14:01:28.844+0000] {clientserver.py:529} INFO - Error while sending or receiving.
Traceback (most recent call last):
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py", line 527, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [Errno 104] Connection reset by peer
[2025-07-05T14:01:28.845+0000] {clientserver.py:570} INFO - Closing down clientserver connection
[2025-07-05T14:01:28.846+0000] {java_gateway.py:1056} INFO - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py", line 527, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py", line 530, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending
[2025-07-05T14:01:28.848+0000] {clientserver.py:570} INFO - Closing down clientserver connection
[2025-07-05T14:01:29.594+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|31.12.2017;395775...|
|31.12.2017;15423;...|
|31.12.2017;298332...|
|31.12.2017;17434;...|
|31.12.2017;310405...|
|31.12.2017;22798;...|
|31.12.2017;13800;...|
|31.12.2017;13905;...|
|31.12.2017;40266;...|
|31.12.2017;341567...|
|31.12.2017;14912;...|
|31.12.2017;13871;...|
|31.12.2017;364395...|
|31.12.2017;14138;...|
|31.12.2017;17441;...|
|31.12.2017;18164;...|
|31.12.2017;14878;...|
|31.12.2017;341569...|
|31.12.2017;14913;...|
|31.12.2017;18007;...|
+--------------------+
only showing top 20 rows
[2025-07-05T14:01:33.902+0000] {logging_mixin.py:188} INFO - +----------+------+-------------------------------------------+-------+
|timestamp |status|message                                    |obj_num|
+----------+------+-------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_ft_balance_f|115    |
+----------+------+-------------------------------------------+-------+
[2025-07-05T14:01:37.785+0000] {logging_mixin.py:188} WARNING - {"ts": "2025-07-05 14:01:37.784", "level": "ERROR", "logger": "SQLQueryContextLogger", "msg": "The number of inserted values cannot match the fields.", "context": {"errorClass": "_LEGACY_ERROR_TEMP_0006"}, "exception": {"class": "Py4JJavaError", "msg": "An error occurred while calling o34.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.ft_balance_f AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_ft_balance_f AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.on_date = source.on_date AND target.account_rk = source.account_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_rk = source.currency_rk, target.balance_out = source.balance_out\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_rk, balance_out)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.currency_rk, source.balance_out, source.on_date, source.account_rk)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)\n\tat scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)\n\tat scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)\n\tat scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)\n\tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n", "stacktrace": [{"class": null, "method": "deco", "file": "/home/***/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", "line": "282"}, {"class": null, "method": "get_return_value", "file": "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", "line": "327"}]}}
[2025-07-05T14:01:37.784+0000] {logger.py:289} ERROR - The number of inserted values cannot match the fields.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o34.sql.
: org.apache.spark.sql.catalyst.parser.ParseException: 
The number of inserted values cannot match the fields.
== SQL (line 2, position 5) ==
    MERGE INTO ds.ft_balance_f AS target
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    USING ds.temp_ft_balance_f AS source
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ON target.on_date = source.on_date AND target.account_rk = source.account_rk
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^
        UPDATE SET target.currency_rk = source.currency_rk, target.balance_out = source.balance_out
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN NOT MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^^^^^
        INSERT (currency_rk, balance_out)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        VALUES (source.currency_rk, source.balance_out, source.on_date, source.account_rk)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	at org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)
	at scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)
	at scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)
	at scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)
	at org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)
	at org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)
	at scala.Option.map(Option.scala:242)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)

[2025-07-05T14:01:37.975+0000] {logging_mixin.py:188} INFO - +----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|timestamp |status|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |obj_num|
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.ft_balance_f: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.ft_balance_f AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_ft_balance_f AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.on_date = source.on_date AND target.account_rk = source.account_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_rk = source.currency_rk, target.balance_out = source.balance_out\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_rk, balance_out)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.currency_rk, source.balance_out, source.on_date, source.account_rk)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n|115    |
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
[2025-07-05T14:01:38.354+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|09-01-2018;873663...|
|09-01-2018;176169...|
|09-01-2018;409685...|
|09-01-2018;156987...|
|09-01-2018;120483...|
|09-01-2018;311159...|
|10-01-2018;873663...|
|10-01-2018;393808...|
|10-01-2018;37051;...|
|10-01-2018;13630;...|
|10-01-2018;37051;...|
|10-01-2018;176270...|
|10-01-2018;393808...|
|11-01-2018;13630;...|
|11-01-2018;434141...|
|11-01-2018;311161...|
|11-01-2018;37051;...|
|11-01-2018;176169...|
|12-01-2018;393808...|
|12-01-2018;434141...|
+--------------------+
only showing top 20 rows
[2025-07-05T14:01:50.487+0000] {logging_mixin.py:188} INFO - +----------+------+-------------------------------------------+-------+
|timestamp |status|message                                    |obj_num|
+----------+------+-------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_ft_posting_f|33893  |
+----------+------+-------------------------------------------+-------+
[2025-07-05T14:01:52.562+0000] {logging_mixin.py:188} INFO - +----------+------+--------------------------------------------------------+-------+
|timestamp |status|message                                                 |obj_num|
+----------+------+--------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.ft_posting_f: 'ft_posting_f'|33893  |
+----------+------+--------------------------------------------------------+-------+
[2025-07-05T14:01:52.703+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
|2018-01-01;2018-0...|
+--------------------+
only showing top 20 rows
[2025-07-05T14:01:55.847+0000] {logging_mixin.py:188} INFO - +----------+------+-------------------------------------------+-------+
|timestamp |status|message                                    |obj_num|
+----------+------+-------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_md_account_d|113    |
+----------+------+-------------------------------------------+-------+
[2025-07-05T14:01:59.713+0000] {logging_mixin.py:188} WARNING - {"ts": "2025-07-05 14:01:59.712", "level": "ERROR", "logger": "SQLQueryContextLogger", "msg": "The number of inserted values cannot match the fields.", "context": {"errorClass": "_LEGACY_ERROR_TEMP_0006"}, "exception": {"class": "Py4JJavaError", "msg": "An error occurred while calling o34.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_account_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_account_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.data_actual_date = source.data_actual_date AND target.account_rk = source.account_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_code = source.currency_code, target.char_type = source.char_type, target.data_actual_end_date = source.data_actual_end_date, target.currency_rk = source.currency_rk, target.account_number = source.account_number\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_code, char_type, data_actual_end_date, currency_rk, account_number)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.account_rk, source.currency_code, source.data_actual_date, source.char_type, source.data_actual_end_date, source.currency_rk, source.account_number)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)\n\tat scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)\n\tat scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)\n\tat scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)\n\tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n", "stacktrace": [{"class": null, "method": "deco", "file": "/home/***/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", "line": "282"}, {"class": null, "method": "get_return_value", "file": "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", "line": "327"}]}}
[2025-07-05T14:01:59.712+0000] {logger.py:289} ERROR - The number of inserted values cannot match the fields.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o34.sql.
: org.apache.spark.sql.catalyst.parser.ParseException: 
The number of inserted values cannot match the fields.
== SQL (line 2, position 5) ==
    MERGE INTO ds.md_account_d AS target
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    USING ds.temp_md_account_d AS source
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ON target.data_actual_date = source.data_actual_date AND target.account_rk = source.account_rk
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^
        UPDATE SET target.currency_code = source.currency_code, target.char_type = source.char_type, target.data_actual_end_date = source.data_actual_end_date, target.currency_rk = source.currency_rk, target.account_number = source.account_number
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN NOT MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^^^^^
        INSERT (currency_code, char_type, data_actual_end_date, currency_rk, account_number)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        VALUES (source.account_rk, source.currency_code, source.data_actual_date, source.char_type, source.data_actual_end_date, source.currency_rk, source.account_number)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	at org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)
	at scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)
	at scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)
	at scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)
	at org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)
	at org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)
	at scala.Option.map(Option.scala:242)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)

[2025-07-05T14:01:59.917+0000] {logging_mixin.py:188} INFO - +----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|timestamp |status|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |obj_num|
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.md_account_d: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_account_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_account_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.data_actual_date = source.data_actual_date AND target.account_rk = source.account_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_code = source.currency_code, target.char_type = source.char_type, target.data_actual_end_date = source.data_actual_end_date, target.currency_rk = source.currency_rk, target.account_number = source.account_number\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_code, char_type, data_actual_end_date, currency_rk, account_number)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.account_rk, source.currency_code, source.data_actual_date, source.char_type, source.data_actual_end_date, source.currency_rk, source.account_number)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n|113    |
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
[2025-07-05T14:02:00.059+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|37;2017-05-11;205...|
|40;2017-05-11;205...|
|529511969;2017-12...|
|CURRENCY_RK;DATA_...|
|63;2017-05-11;205...|
|26;2017-05-11;205...|
|29;2017-05-11;205...|
|38;2017-05-11;205...|
|46;2017-05-11;205...|
|35;2017-05-11;205...|
|39;2017-05-11;205...|
|30;2017-05-11;205...|
|48;2017-05-11;205...|
|52;2017-05-11;205...|
|56;2017-05-11;205...|
|59;2017-05-11;205...|
|60;2017-05-11;205...|
|32;2017-05-11;205...|
|23;2017-05-11;205...|
|25;2017-05-11;205...|
+--------------------+
only showing top 20 rows
[2025-07-05T14:02:03.330+0000] {logging_mixin.py:188} INFO - +----------+------+--------------------------------------------+-------+
|timestamp |status|message                                     |obj_num|
+----------+------+--------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_md_currency_d|51     |
+----------+------+--------------------------------------------+-------+
[2025-07-05T14:02:07.079+0000] {logging_mixin.py:188} WARNING - {"ts": "2025-07-05 14:02:07.078", "level": "ERROR", "logger": "SQLQueryContextLogger", "msg": "The number of inserted values cannot match the fields.", "context": {"errorClass": "_LEGACY_ERROR_TEMP_0006"}, "exception": {"class": "Py4JJavaError", "msg": "An error occurred while calling o34.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_currency_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_currency_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.currency_rk = source.currency_rk AND target.data_actual_date = source.data_actual_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_code = source.currency_code, target.code_iso_char = source.code_iso_char, target.data_actual_end_date = source.data_actual_end_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_code, code_iso_char, data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.data_actual_date, source.currency_code, source.currency_rk, source.code_iso_char, source.data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)\n\tat scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)\n\tat scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)\n\tat scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)\n\tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n", "stacktrace": [{"class": null, "method": "deco", "file": "/home/***/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", "line": "282"}, {"class": null, "method": "get_return_value", "file": "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", "line": "327"}]}}
[2025-07-05T14:02:07.078+0000] {logger.py:289} ERROR - The number of inserted values cannot match the fields.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o34.sql.
: org.apache.spark.sql.catalyst.parser.ParseException: 
The number of inserted values cannot match the fields.
== SQL (line 2, position 5) ==
    MERGE INTO ds.md_currency_d AS target
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    USING ds.temp_md_currency_d AS source
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ON target.currency_rk = source.currency_rk AND target.data_actual_date = source.data_actual_date
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^
        UPDATE SET target.currency_code = source.currency_code, target.code_iso_char = source.code_iso_char, target.data_actual_end_date = source.data_actual_end_date
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN NOT MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^^^^^
        INSERT (currency_code, code_iso_char, data_actual_end_date)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        VALUES (source.data_actual_date, source.currency_code, source.currency_rk, source.code_iso_char, source.data_actual_end_date)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	at org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)
	at scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)
	at scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)
	at scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)
	at org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)
	at org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)
	at scala.Option.map(Option.scala:242)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)

[2025-07-05T14:02:07.234+0000] {logging_mixin.py:188} INFO - +----------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|timestamp |status|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |obj_num|
+----------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.md_currency_d: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_currency_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_currency_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.currency_rk = source.currency_rk AND target.data_actual_date = source.data_actual_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.currency_code = source.currency_code, target.code_iso_char = source.code_iso_char, target.data_actual_end_date = source.data_actual_end_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (currency_code, code_iso_char, data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.data_actual_date, source.currency_code, source.currency_rk, source.code_iso_char, source.data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n|51     |
+----------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
[2025-07-05T14:02:07.381+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|2018-01-30;2018-0...|
|2018-01-19;2018-0...|
|2018-01-10;2018-0...|
|2018-01-12;2018-0...|
|2018-01-12;2018-0...|
|2018-01-27;2018-0...|
|2018-01-10;2018-0...|
|2018-01-10;2018-0...|
|2018-01-25;2018-0...|
|2018-01-20;2018-0...|
|2018-01-13;2018-0...|
|DATA_ACTUAL_DATE;...|
|2018-01-17;2018-0...|
|2018-01-20;2018-0...|
|2018-01-18;2018-0...|
|2018-01-16;2018-0...|
|2018-01-12;2018-0...|
|2018-01-11;2018-0...|
|2017-12-30;2018-0...|
|2018-01-23;2018-0...|
+--------------------+
only showing top 20 rows
[2025-07-05T14:02:10.730+0000] {logging_mixin.py:188} INFO - +----------+------+-------------------------------------------------+-------+
|timestamp |status|message                                          |obj_num|
+----------+------+-------------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_md_exchange_rate_d|461    |
+----------+------+-------------------------------------------------+-------+
[2025-07-05T14:02:14.455+0000] {logging_mixin.py:188} WARNING - {"ts": "2025-07-05 14:02:14.454", "level": "ERROR", "logger": "SQLQueryContextLogger", "msg": "The number of inserted values cannot match the fields.", "context": {"errorClass": "_LEGACY_ERROR_TEMP_0006"}, "exception": {"class": "Py4JJavaError", "msg": "An error occurred while calling o34.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_exchange_rate_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_exchange_rate_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.data_actual_date = source.data_actual_date AND target.currency_rk = source.currency_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.code_iso_num = source.code_iso_num, target.reduced_cource = source.reduced_cource, target.data_actual_end_date = source.data_actual_end_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (code_iso_num, reduced_cource, data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.currency_rk, source.code_iso_num, source.reduced_cource, source.data_actual_end_date, source.data_actual_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)\n\tat scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)\n\tat scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)\n\tat scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)\n\tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n", "stacktrace": [{"class": null, "method": "deco", "file": "/home/***/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", "line": "282"}, {"class": null, "method": "get_return_value", "file": "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", "line": "327"}]}}
[2025-07-05T14:02:14.454+0000] {logger.py:289} ERROR - The number of inserted values cannot match the fields.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o34.sql.
: org.apache.spark.sql.catalyst.parser.ParseException: 
The number of inserted values cannot match the fields.
== SQL (line 2, position 5) ==
    MERGE INTO ds.md_exchange_rate_d AS target
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    USING ds.temp_md_exchange_rate_d AS source
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ON target.data_actual_date = source.data_actual_date AND target.currency_rk = source.currency_rk
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^
        UPDATE SET target.code_iso_num = source.code_iso_num, target.reduced_cource = source.reduced_cource, target.data_actual_end_date = source.data_actual_end_date
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN NOT MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^^^^^
        INSERT (code_iso_num, reduced_cource, data_actual_end_date)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        VALUES (source.currency_rk, source.code_iso_num, source.reduced_cource, source.data_actual_end_date, source.data_actual_date)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	at org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)
	at scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)
	at scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)
	at scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)
	at org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)
	at org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)
	at scala.Option.map(Option.scala:242)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)

[2025-07-05T14:02:14.611+0000] {logging_mixin.py:188} INFO - +----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|timestamp |status|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |obj_num|
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.md_exchange_rate_d: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_exchange_rate_d AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_exchange_rate_d AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.data_actual_date = source.data_actual_date AND target.currency_rk = source.currency_rk\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.code_iso_num = source.code_iso_num, target.reduced_cource = source.reduced_cource, target.data_actual_end_date = source.data_actual_end_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (code_iso_num, reduced_cource, data_actual_end_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.currency_rk, source.code_iso_num, source.reduced_cource, source.data_actual_end_date, source.data_actual_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n|461    |
+----------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
[2025-07-05T14:02:14.732+0000] {logging_mixin.py:188} INFO - +--------------------+
|                 _c0|
+--------------------+
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|CHAPTER;CHAPTER_N...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
|А;Балансовые счет...|
+--------------------+
[2025-07-05T14:02:17.906+0000] {logging_mixin.py:188} INFO - +----------+------+--------------------------------------------------+-------+
|timestamp |status|message                                           |obj_num|
+----------+------+--------------------------------------------------+-------+
|2025-07-05|ИНФО  |создана временная таблица temp_md_ledger_account_s|19     |
+----------+------+--------------------------------------------------+-------+
[2025-07-05T14:02:21.651+0000] {logging_mixin.py:188} WARNING - {"ts": "2025-07-05 14:02:21.607", "level": "ERROR", "logger": "SQLQueryContextLogger", "msg": "The number of inserted values cannot match the fields.", "context": {"errorClass": "_LEGACY_ERROR_TEMP_0006"}, "exception": {"class": "Py4JJavaError", "msg": "An error occurred while calling o34.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_ledger_account_s AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_ledger_account_s AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.ledger_account = source.ledger_account AND target.start_date = source.start_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.section_number = source.section_number, target.is_reserved = source.is_reserved, target.chapter_name = source.chapter_name, target.is_rub_only = source.is_rub_only, target.ledger_account_name = source.ledger_account_name, target.is_reserved_assets = source.is_reserved_assets, target.min_term = source.min_term, target.ledger1_account = source.ledger1_account, target.min_term_measure = source.min_term_measure, target.chapter = source.chapter, target.is_correct = source.is_correct, target.characteristic = source.characteristic, target.is_resident = source.is_resident, target.is_revaluation = source.is_revaluation, target.subsection_name = source.subsection_name, target.max_term_measure = source.max_term_measure, target.pair_account = source.pair_account, target.end_date = source.end_date, target.is_interest = source.is_interest, target.is_loan = source.is_loan, target.section_name = source.section_name, target.ledger1_account_name = source.ledger1_account_name, target.is_overdue = source.is_overdue, target.max_term = source.max_term, target.is_reserve = source.is_reserve, target.ledger_acc_full_name_translit = source.ledger_acc_full_name_translit\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (section_number, is_reserved, chapter_name, is_rub_only, ledger_account_name, is_reserved_assets, min_term, ledger1_account, min_term_measure, chapter, is_correct, characteristic, is_resident, is_revaluation, subsection_name, max_term_measure, pair_account, end_date, is_interest, is_loan, section_name, ledger1_account_name, is_overdue, max_term, is_reserve, ledger_acc_full_name_translit)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.section_number, source.is_reserved, source.ledger_account, source.chapter_name, source.is_rub_only, source.ledger_account_name, source.is_reserved_assets, source.min_term, source.ledger1_account, source.min_term_measure, source.chapter, source.is_correct, source.characteristic, source.is_resident, source.is_revaluation, source.subsection_name, source.max_term_measure, source.pair_account, source.end_date, source.is_interest, source.is_loan, source.section_name, source.ledger1_account_name, source.is_overdue, source.max_term, source.is_reserve, source.ledger_acc_full_name_translit, source.start_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)\n\tat scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)\n\tat scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)\n\tat scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)\n\tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n", "stacktrace": [{"class": null, "method": "deco", "file": "/home/***/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", "line": "282"}, {"class": null, "method": "get_return_value", "file": "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", "line": "327"}]}}
[2025-07-05T14:02:21.607+0000] {logger.py:289} ERROR - The number of inserted values cannot match the fields.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/spark/spark-4.0.0-bin-hadoop3/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o34.sql.
: org.apache.spark.sql.catalyst.parser.ParseException: 
The number of inserted values cannot match the fields.
== SQL (line 2, position 5) ==
    MERGE INTO ds.md_ledger_account_s AS target
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    USING ds.temp_md_ledger_account_s AS source
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ON target.ledger_account = source.ledger_account AND target.start_date = source.start_date
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^
        UPDATE SET target.section_number = source.section_number, target.is_reserved = source.is_reserved, target.chapter_name = source.chapter_name, target.is_rub_only = source.is_rub_only, target.ledger_account_name = source.ledger_account_name, target.is_reserved_assets = source.is_reserved_assets, target.min_term = source.min_term, target.ledger1_account = source.ledger1_account, target.min_term_measure = source.min_term_measure, target.chapter = source.chapter, target.is_correct = source.is_correct, target.characteristic = source.characteristic, target.is_resident = source.is_resident, target.is_revaluation = source.is_revaluation, target.subsection_name = source.subsection_name, target.max_term_measure = source.max_term_measure, target.pair_account = source.pair_account, target.end_date = source.end_date, target.is_interest = source.is_interest, target.is_loan = source.is_loan, target.section_name = source.section_name, target.ledger1_account_name = source.ledger1_account_name, target.is_overdue = source.is_overdue, target.max_term = source.max_term, target.is_reserve = source.is_reserve, target.ledger_acc_full_name_translit = source.ledger_acc_full_name_translit
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    WHEN NOT MATCHED THEN
^^^^^^^^^^^^^^^^^^^^^^^^^
        INSERT (section_number, is_reserved, chapter_name, is_rub_only, ledger_account_name, is_reserved_assets, min_term, ledger1_account, min_term_measure, chapter, is_correct, characteristic, is_resident, is_revaluation, subsection_name, max_term_measure, pair_account, end_date, is_interest, is_loan, section_name, ledger1_account_name, is_overdue, max_term, is_reserve, ledger_acc_full_name_translit)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        VALUES (source.section_number, source.is_reserved, source.ledger_account, source.chapter_name, source.is_rub_only, source.ledger_account_name, source.is_reserved_assets, source.min_term, source.ledger1_account, source.min_term_measure, source.chapter, source.is_correct, source.characteristic, source.is_resident, source.is_revaluation, source.subsection_name, source.max_term_measure, source.pair_account, source.end_date, source.is_interest, source.is_loan, source.section_name, source.ledger1_account_name, source.is_overdue, source.max_term, source.is_reserve, source.ledger_acc_full_name_translit, source.start_date)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	at org.apache.spark.sql.errors.QueryParsingErrors$.insertedValueNumberNotMatchFieldNumberError(QueryParsingErrors.scala:59)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$7(AstBuilder.scala:1057)
	at scala.collection.StrictOptimizedIterableOps.map(StrictOptimizedIterableOps.scala:100)
	at scala.collection.StrictOptimizedIterableOps.map$(StrictOptimizedIterableOps.scala:87)
	at scala.collection.convert.JavaCollectionWrappers$JListWrapper.map(JavaCollectionWrappers.scala:138)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitMergeIntoTable$1(AstBuilder.scala:1047)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:1013)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitMergeIntoTable(AstBuilder.scala:63)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$MergeIntoTableContext.accept(SqlBaseParser.java:12989)
	at org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:37)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:686)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitDmlStatement$1(AstBuilder.scala:704)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitDmlStatement(AstBuilder.scala:703)
	at org.apache.spark.sql.catalyst.parser.SqlBaseParser$DmlStatementContext.accept(SqlBaseParser.java:3896)
	at org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$3(AstBuilder.scala:651)
	at scala.Option.map(Option.scala:242)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:651)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:652)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$3(AstBuilder.scala:155)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCompoundOrSingleStatement$1(AstBuilder.scala:155)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AstBuilder.visitCompoundOrSingleStatement(AstBuilder.scala:154)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$withErrorHandling$1(AbstractSqlParser.scala:116)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:170)
	at org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:155)
	at org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:41)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.withErrorHandling(AbstractSqlParser.scala:115)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:96)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:81)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:93)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$2(SparkSession.scala:451)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.classic.SparkSession.$anonfun$sql$1(SparkSession.scala:450)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:449)
	at org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:467)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)

[2025-07-05T14:02:21.875+0000] {logging_mixin.py:188} INFO - +----------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|timestamp |status|message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |obj_num|
+----------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
|2025-07-05|ОШИБКА|ошибка перелива данных в ds.md_ledger_account_s: \nThe number of inserted values cannot match the fields.\n== SQL (line 2, position 5) ==\n    MERGE INTO ds.md_ledger_account_s AS target\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    USING ds.temp_md_ledger_account_s AS source\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ON target.ledger_account = source.ledger_account AND target.start_date = source.start_date\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^\n        UPDATE SET target.section_number = source.section_number, target.is_reserved = source.is_reserved, target.chapter_name = source.chapter_name, target.is_rub_only = source.is_rub_only, target.ledger_account_name = source.ledger_account_name, target.is_reserved_assets = source.is_reserved_assets, target.min_term = source.min_term, target.ledger1_account = source.ledger1_account, target.min_term_measure = source.min_term_measure, target.chapter = source.chapter, target.is_correct = source.is_correct, target.characteristic = source.characteristic, target.is_resident = source.is_resident, target.is_revaluation = source.is_revaluation, target.subsection_name = source.subsection_name, target.max_term_measure = source.max_term_measure, target.pair_account = source.pair_account, target.end_date = source.end_date, target.is_interest = source.is_interest, target.is_loan = source.is_loan, target.section_name = source.section_name, target.ledger1_account_name = source.ledger1_account_name, target.is_overdue = source.is_overdue, target.max_term = source.max_term, target.is_reserve = source.is_reserve, target.ledger_acc_full_name_translit = source.ledger_acc_full_name_translit\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    WHEN NOT MATCHED THEN\n^^^^^^^^^^^^^^^^^^^^^^^^^\n        INSERT (section_number, is_reserved, chapter_name, is_rub_only, ledger_account_name, is_reserved_assets, min_term, ledger1_account, min_term_measure, chapter, is_correct, characteristic, is_resident, is_revaluation, subsection_name, max_term_measure, pair_account, end_date, is_interest, is_loan, section_name, ledger1_account_name, is_overdue, max_term, is_reserve, ledger_acc_full_name_translit)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        VALUES (source.section_number, source.is_reserved, source.ledger_account, source.chapter_name, source.is_rub_only, source.ledger_account_name, source.is_reserved_assets, source.min_term, source.ledger1_account, source.min_term_measure, source.chapter, source.is_correct, source.characteristic, source.is_resident, source.is_revaluation, source.subsection_name, source.max_term_measure, source.pair_account, source.end_date, source.is_interest, source.is_loan, source.section_name, source.ledger1_account_name, source.is_overdue, source.max_term, source.is_reserve, source.ledger_acc_full_name_translit, source.start_date)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n|19     |
+----------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+
[2025-07-05T14:02:21.877+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-05T14:02:21.877+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-05T14:02:21.883+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=practice_etl_pipeline, task_id=transform_and_load, run_id=manual__2025-07-05T14:01:18.047993+00:00, execution_date=20250705T140118, start_date=20250705T140128, end_date=20250705T140221
[2025-07-05T14:02:21.924+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-05T14:02:21.938+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-05T14:02:21.940+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
